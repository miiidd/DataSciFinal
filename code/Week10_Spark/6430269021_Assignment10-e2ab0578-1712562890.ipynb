{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Preparation\n",
    "We check if we are in Google Colab.  If this is the case, install all necessary packages.\n",
    "\n",
    "To run spark in Colab, we need to first install all the dependencies in Colab environment i.e. Apache Spark 3.3.2 with hadoop 3.3, Java 8 and Findspark to locate the spark in the system. The tools installation can be carried out inside the Jupyter Notebook of the Colab.\n",
    "Learn more from [A Must-Read Guide on How to Work with PySpark on Google Colab for Data Scientists!](https://www.analyticsvidhya.com/blog/2020/11/a-must-read-guide-on-how-to-work-with-pyspark-on-google-colab-for-data-scientists/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "    !wget -q https://dlcdn.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
    "    !tar xf spark-3.3.2-bin-hadoop3.tgz\n",
    "    !mv spark-3.3.2-bin-hadoop3 spark\n",
    "    !pip install -q findspark\n",
    "    import os\n",
    "    os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "    os.environ[\"SPARK_HOME\"] = \"/content/spark\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q findspark pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start a Local Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark_url = 'local'\n",
    "spark = SparkSession.builder.master(spark_url).appName(\"MyApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Assignment\n",
    "\n",
    "Based on the movie review dataset in 'netflix-rotten-tomatoes-metacritic-imdb.csv', answer the below questions.\n",
    "\n",
    "**Note:** do not clean or remove missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+----------------+---------------+----------------+--------------------+------------+---------------+--------------------+--------------------+-----------+----------+---------------------+----------------+---------------+--------------------+----------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------+\n",
      "|              Title|               Genre|                Tags|       Languages|Series or Movie|Hidden Gem Score|Country Availability|     Runtime|       Director|              Writer|              Actors|View Rating|IMDb Score|Rotten Tomatoes Score|Metacritic Score|Awards Received|Awards Nominated For| Boxoffice|Release Date|Netflix Release Date|    Production House|        Netflix Link|           IMDb Link|             Summary|IMDb Votes|               Image|              Poster|        TMDb Trailer|Trailer Site|\n",
      "+-------------------+--------------------+--------------------+----------------+---------------+----------------+--------------------+------------+---------------+--------------------+--------------------+-----------+----------+---------------------+----------------+---------------+--------------------+----------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------+\n",
      "|   Lets Fight Ghost|Crime, Drama, Fan...|Comedy Programmes...|Swedish, Spanish|         Series|             4.3|            Thailand|< 30 minutes|Tomas Alfredson|John Ajvide Lindq...|KÃ¥re Hedebrant, P...|          R|       7.9|                 98.0|            82.0|           74.0|                57.0|$2,122,065| 12 Dec 2008|          2021-03-04|Canal+, Sandrew M...|https://www.netfl...|https://www.imdb....|A med student wit...|  205926.0|https://occ-0-470...|https://m.media-a...|                NULL|        NULL|\n",
      "|HOW TO BUILD A GIRL|              Comedy|Dramas,Comedies,F...|         English|          Movie|             7.0|              Canada|    1-2 hour|  Coky Giedroyc|       Caitlin Moran|Paddy Considine, ...|          R|       5.8|                 79.0|            69.0|            1.0|                NULL|   $70,632| 08 May 2020|          2021-03-04|Film 4, Monumenta...|https://www.netfl...|https://www.imdb....|When nerdy Johann...|    2838.0|https://occ-0-108...|https://m.media-a...|https://www.youtu...|     YouTube|\n",
      "|         Centigrade|     Drama, Thriller|           Thrillers|         English|          Movie|             6.4|              Canada|    1-2 hour|  Brendan Walsh|Brendan Walsh, Da...|Genesis Rodriguez...|    Unrated|       4.3|                 NULL|            46.0|           NULL|                NULL|   $16,263| 28 Aug 2020|          2021-03-04|                NULL|https://www.netfl...|https://www.imdb....|Trapped in a froz...|    1720.0|https://occ-0-108...|https://m.media-a...|https://www.youtu...|     YouTube|\n",
      "+-------------------+--------------------+--------------------+----------------+---------------+----------------+--------------------+------------+---------------+--------------------+--------------------+-----------+----------+---------------------+----------------+---------------+--------------------+----------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'netflix-rotten-tomatoes-metacritic-imdb.csv'\n",
    "df = spark.read.option(\"delemiter\",\";\").option(\"header\",True).csv(path)\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the maximum and average of the overall hidden gem score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(max(Hidden Gem Score)='9.8')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_hidden_gem_score = df.select('Hidden Gem Score').agg({\"Hidden Gem Score\":'max'}).collect()[0][0]\n",
    "# df.select('Hidden Gem Score').agg({\"Hidden Gem Score\":'max'}).collect()\n",
    "avg_hidden_gem_score = df.select('Hidden Gem Score').agg({\"Hidden Gem Score\":'avg'}).collect()[0][0]\n",
    "print(max_hidden_gem_score,avg_hidden_gem_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many movies that are available in Korea?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735\n"
     ]
    }
   ],
   "source": [
    "# df[df['Languages'].contains('Korean')].count()\n",
    "print(df.filter(df['Languages'].contains('Korean')).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which director has the highest average hidden gem score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dorin Marcu\n"
     ]
    }
   ],
   "source": [
    "print(df.groupBy('Director').agg({'Hidden Gem Score':'avg'}).orderBy('avg(Hidden Gem Score)',ascending=False).first()['Director'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many genres are there in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[DATATYPE_MISMATCH.FILTER_NOT_BOOLEAN] Cannot resolve \"split(Genre, , , -1)\" due to data type mismatch: Filter expression \"split(Genre, , , -1)\" of type \"ARRAY<STRING>\" is not a boolean.;\nFilter split(Genre#18, , , -1)\n+- Relation [Title#17,Genre#18,Tags#19,Languages#20,Series or Movie#21,Hidden Gem Score#22,Country Availability#23,Runtime#24,Director#25,Writer#26,Actors#27,View Rating#28,IMDb Score#29,Rotten Tomatoes Score#30,Metacritic Score#31,Awards Received#32,Awards Nominated For#33,Boxoffice#34,Release Date#35,Netflix Release Date#36,Production House#37,Netflix Link#38,IMDb Link#39,Summary#40,... 5 more fields] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split,explode\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGenre\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# genre_df = df.withColumn('Genre',split(df['Genre'],', '))\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# genre_df.show(3)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# print(genre.count())\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\sql\\dataframe.py:3081\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   3079\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n\u001b[0;32m   3080\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, Column):\n\u001b[1;32m-> 3081\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3082\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m   3083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;241m*\u001b[39mitem)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\sql\\dataframe.py:3329\u001b[0m, in \u001b[0;36mDataFrame.filter\u001b[1;34m(self, condition)\u001b[0m\n\u001b[0;32m   3327\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mfilter(condition)\n\u001b[0;32m   3328\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(condition, Column):\n\u001b[1;32m-> 3329\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m   3332\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN_OR_STR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3333\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(condition)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m   3334\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [DATATYPE_MISMATCH.FILTER_NOT_BOOLEAN] Cannot resolve \"split(Genre, , , -1)\" due to data type mismatch: Filter expression \"split(Genre, , , -1)\" of type \"ARRAY<STRING>\" is not a boolean.;\nFilter split(Genre#18, , , -1)\n+- Relation [Title#17,Genre#18,Tags#19,Languages#20,Series or Movie#21,Hidden Gem Score#22,Country Availability#23,Runtime#24,Director#25,Writer#26,Actors#27,View Rating#28,IMDb Score#29,Rotten Tomatoes Score#30,Metacritic Score#31,Awards Received#32,Awards Nominated For#33,Boxoffice#34,Release Date#35,Netflix Release Date#36,Production House#37,Netflix Link#38,IMDb Link#39,Summary#40,... 5 more fields] csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split,explode\n",
    "\n",
    "genre_df = df.withColumn('Genre',split(df['Genre'],', ')) #replace column\n",
    "# genre_df.show(3)\n",
    "\n",
    "# genre = genre_df.select(explode(genre_df['Genre'])).distinct()\n",
    "# genre.show(3)\n",
    "\n",
    "# print(genre.count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
